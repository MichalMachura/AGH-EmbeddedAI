{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa5b3a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pynq-dpu in /usr/local/share/pynq-venv/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: mnist in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynq-dpu) (0.2.2)\n",
      "Requirement already satisfied: pybind11 in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynq-dpu) (2.8.0)\n",
      "Requirement already satisfied: pynq>=2.7.0 in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynq-dpu) (3.0.1)\n",
      "Requirement already satisfied: CppHeaderParser in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynq-dpu) (2.7.4)\n",
      "Requirement already satisfied: cffi in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynq>=2.7.0->pynq-dpu) (1.14.5)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynq>=2.7.0->pynq-dpu) (1.5.1)\n",
      "Requirement already satisfied: numpy in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynq>=2.7.0->pynq-dpu) (1.20.3)\n",
      "Requirement already satisfied: pynqmetadata>=0.0.1 in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynq>=2.7.0->pynq-dpu) (0.1.5)\n",
      "Requirement already satisfied: pynqutils>=0.0.1 in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynq>=2.7.0->pynq-dpu) (0.1.1)\n",
      "Requirement already satisfied: setuptools>=24.2.0 in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynq>=2.7.0->pynq-dpu) (44.0.0)\n",
      "Requirement already satisfied: ply in /usr/lib/python3/dist-packages (from CppHeaderParser->pynq-dpu) (3.11)\n",
      "Requirement already satisfied: jsonschema>=3.2.0 in /usr/lib/python3/dist-packages (from pynqmetadata>=0.0.1->pynq>=2.7.0->pynq-dpu) (3.2.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynqmetadata>=0.0.1->pynq>=2.7.0->pynq-dpu) (1.10.2)\n",
      "Requirement already satisfied: python-magic>=0.4.25 in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynqutils>=0.0.1->pynq>=2.7.0->pynq-dpu) (0.4.27)\n",
      "Requirement already satisfied: tqdm in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pynqutils>=0.0.1->pynq>=2.7.0->pynq-dpu) (4.62.3)\n",
      "Requirement already satisfied: pycparser in /usr/lib/python3/dist-packages (from cffi->pynq>=2.7.0->pynq-dpu) (2.19)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/share/pynq-venv/lib/python3.8/site-packages (from pydantic->pynqmetadata>=0.0.1->pynq>=2.7.0->pynq-dpu) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "# !python3 -m pip install pynq-dpu --no-use-pep517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635f5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "# sys.path.append(\"/usr/include/vart\")\n",
    "# sys.path.append(\"/usr/include/xir\")\n",
    "import numpy as np\n",
    "import platform\n",
    "import tqdm\n",
    "from typing import Tuple, List, Union, Any\n",
    "import pynq_dpu\n",
    "import pynq\n",
    "\n",
    "# pynq.pl_server.xrt_device._xrt_version = (2, 8, 0)\n",
    "\n",
    "class EvalLoader:\n",
    "    def __init__(self, \n",
    "                 batch_size: int = 1, \n",
    "                 npz_path: str = 'eval_data.npz') -> None:\n",
    "        data = np.load(npz_path)\n",
    "        self.data = data['data'].astype(np.float32) / 255\n",
    "        self.targets = data['targets']\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i >= len(self):\n",
    "            raise StopIteration\n",
    "\n",
    "        beg = min(i * self.batch_size, self.data.shape[0])\n",
    "        end = min(beg + self.batch_size, self.data.shape[0])\n",
    "\n",
    "        return self.data[beg:end, ...], self.targets[beg:end]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] // self.batch_size\n",
    "\n",
    "\n",
    "class TimeMeasurement:\n",
    "    def __init__(self, context_name: str, frames: int) -> None:\n",
    "        self.context_name: str = context_name\n",
    "        self.frames: int = frames\n",
    "        self.begin: float = None\n",
    "        self.end: float = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.begin = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.time()\n",
    "\n",
    "    @property\n",
    "    def time(self) -> float:\n",
    "        if self.begin is None or self.end is None:\n",
    "            raise RuntimeError()\n",
    "        return int(self.end - self.begin)\n",
    "\n",
    "    @property\n",
    "    def fps(self):\n",
    "        return self.frames / self.time\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        t = self.time\n",
    "        h = t // 60\n",
    "        min = (t - h*60) // 60\n",
    "        s = int(t - h*60 - min*60)\n",
    "        ms = int((t - np.floor(t))*1000)\n",
    "\n",
    "        return f\"Execution time: {h}:{min}:{s}:{ms}, processed {self.frames} frames, throughput: {self.fps} fps.\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        t = self.time\n",
    "        h = t // 60\n",
    "        min = (t - h*60) // 60\n",
    "        s = np.floor(t - h*60 - min*60)\n",
    "        ms = np.floor((t - np.floor(t))*1000)\n",
    "\n",
    "        return f'TimeMeasurement(context=\"{self.context_name}\",\"{h}:{min}:{s}:{ms}\", frames={self.frames}, throughput={self.fps})'\n",
    "\n",
    "\n",
    "class AccuracyMetic:\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, y_pred: np.ndarray, y_ref: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        :param y_pred: array of shape (batch_size, num_of_classes) type float\n",
    "        :param y_ref: array with shape (batch_size,) and type Long\n",
    "        :return: scalar as accuracy metric for batch\n",
    "        \"\"\"\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        cmp = y_pred == y_ref\n",
    "        # scalar value\n",
    "        score  = cmp.sum() / cmp.shape[0]\n",
    "\n",
    "        return score\n",
    "\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, \n",
    "                 y_pred: np.ndarray, \n",
    "                 y_ref: np.ndarray\n",
    "                 ) -> Any:\n",
    "        \n",
    "        return 0.0\n",
    "\n",
    "\n",
    "loader = EvalLoader()\n",
    "metric = AccuracyMetic()\n",
    "criterion = CrossEntropyLoss()\n",
    "tm = TimeMeasurement(\"Evaluation on KV260\", loader.batch_size * len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "364364fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vart::Runner@0x22d68b30\n"
     ]
    }
   ],
   "source": [
    "def softmax(x: np.ndarray, axis=1):\n",
    "    x = np.exp(x)\n",
    "    x = x / np.sum(x, axis=axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "class NetworkDPU:\n",
    "    \n",
    "    def __init__(self, xmodel_path: str = 'MiniResnet_VAI.xmodel', dpu_path: str = 'dpu.bit'):\n",
    "        self.ov: pynq_dpu.DpuOverlay = pynq_dpu.DpuOverlay(dpu_path, download=True)\n",
    "        self.ov.load_model(xmodel_path)\n",
    "        self.dpu = self.ov.runner\n",
    "        print(self.ov.runner)\n",
    "        inputTensors = self.dpu.get_input_tensors()\n",
    "        outputTensors = self.dpu.get_output_tensors()\n",
    "        # get list of shapes\n",
    "        shapeIn = np.array([it.dims for it in inputTensors])\n",
    "        shapeOut = np.array([ot.dims for ot in outputTensors])\n",
    "        self.shapeIn = shapeIn\n",
    "        self.shapeOut = shapeOut\n",
    "        self.buff_in = [np.zeros(sh, np.int8, order='C') for sh in shapeIn]\n",
    "        self.buff_out = [np.zeros(sh, np.int8, order='C') for sh in shapeOut]\n",
    "        \n",
    "        self.input_repr = [(it.get_attr('bit_width'), it.get_attr('fix_point')) for it in inputTensors]\n",
    "        self.output_repr = [(ot.get_attr('bit_width'), ot.get_attr('fix_point')) for ot in outputTensors]\n",
    "    \n",
    "    def input_float_to_int8(self, x: np.ndarray) -> np.ndarray:\n",
    "        BIT_WIDTH, PRECISION_BITS = self.input_repr[0]\n",
    "        \n",
    "        # int space \n",
    "        x = x * (2**PRECISION_BITS)\n",
    "        x = np.floor(x)\n",
    "        x = np.clip(x,-128, 127)\n",
    "        x = x.astype(np.int8)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def output_int8_to_float(self, y: np.ndarray):\n",
    "        BIT_WIDTH, PRECISION_BITS = self.output_repr[0]\n",
    "        PRECISION = 1 / 2**PRECISION_BITS\n",
    "        y = y * PRECISION\n",
    "        return y\n",
    "    \n",
    "    def process(self, x: np.ndarray):\n",
    "        x = self.input_float_to_int8(x)\n",
    "        \n",
    "        # fill input buffer\n",
    "        self.buff_in[0] = x\n",
    "        # start DPU thread\n",
    "        job_id = self.dpu.execute_async(self.buff_in, self.buff_out)\n",
    "        # wait for thread end to join it\n",
    "        self.dpu.wait(job_id)\n",
    "        # read from output buffer\n",
    "        y = self.buff_out[0]\n",
    "        \n",
    "        y = self.output_int8_to_float(y)\n",
    "        return y\n",
    "    \n",
    "    def __call__(self, x: np.ndarray) -> Any:\n",
    "        return self.process(x)\n",
    "    \n",
    "net = NetworkDPU(xmodel_path='MiniResnet_VAI.xmodel', \n",
    "                 dpu_path='dpu.bit')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61b7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model: NetworkDPU,\n",
    "               data_loader: EvalLoader,\n",
    "               criterion: CrossEntropyLoss,\n",
    "               metric: AccuracyMetic,\n",
    "               ) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Eval pass generator data through the model.\n",
    "    \n",
    "    :param model: network\n",
    "    :param data_generator: data loader\n",
    "    :param criterion: criterion / loss two arg function\n",
    "    :param metric: metric object - two arg function\n",
    "    :return: loss_value, metric_value\n",
    "    \"\"\"\n",
    "    print(f\"Running on platform: {platform.platform()}, \"\n",
    "          f\"machine: {platform.machine()}, \"\n",
    "          f\"python_version: {platform.python_version()}, \"\n",
    "          f\"processor: {platform.processor()}, \"\n",
    "          f\"system: {platform.system()}, \"\n",
    "          )\n",
    "    total_loss: float = 0.0\n",
    "    total_accuracy: float = 0.0\n",
    "    samples_num: int = 0\n",
    "    \n",
    "    for i, (X, y_ref) in tqdm.tqdm(enumerate(data_loader),):\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(y_pred, y_ref)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        accuracy = metric(y_pred, y_ref)\n",
    "\n",
    "        total_loss += loss * y_pred.shape[0]\n",
    "        total_accuracy += accuracy * y_pred.shape[0]\n",
    "        samples_num += y_pred.shape[0]\n",
    "\n",
    "    if samples_num == 0:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    return total_loss / samples_num, total_accuracy / samples_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c5236e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on platform: Linux-5.4.0-1017-xilinx-zynqmp-aarch64-with-glibc2.29, machine: aarch64, python_version: 3.8.10, processor: aarch64, system: Linux, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:06, 1588.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0:0:6:0, processed 10000 frames, throughput: 1666.6666666666667 fps.\n",
      "Loss:  0.0\n",
      "Accuracy:  0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tm:\n",
    "    loss, acc = evaluation(net, loader, criterion, metric)\n",
    "    \n",
    "print(str(tm))\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8338271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
