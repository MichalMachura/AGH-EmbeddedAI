{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "\n",
    "This tutorial shows the basics of PyTorch library.\n",
    "\n",
    "We design simple Neural Networks for classification task on MNIST dataset.\n",
    "\n",
    "Necessary knowledge you can find in PyTorch documentation:\n",
    "\n",
    "https://pytorch.org/docs/stable/index.html\n",
    "\n",
    "and tutorials:\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "\n",
    "Of course you can use also Google ;)\n",
    "\n",
    "https://github.com/MichalMachura/AGH-EmbeddedAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PyTorch is based on tensor operations.\n",
    "\n",
    "Please create tensors in the following ways:\n",
    "(for all cases use `shape = (1, 3, 28, 28)` - (batch_size, channels, height, width).)\n",
    "\n",
    "a) directly with python list (with any shape) - \n",
    "\n",
    "b) based on numpy array with `shape` - `torch.from_numpy`\n",
    "\n",
    "c) with random values (initialize generator with your academic id / student number from USOS system) -\n",
    "\n",
    "`torch.manual_seed`,`torch.rand`\n",
    "\n",
    "d) linear space in range from -5 to 15 and number of elements to achieve `shape` - `torch.linspace`\n",
    "\n",
    "e) 3 tensors (`x1,x2,x2`) with indices of each element of grid for dimensions: 1, 2, 3 (without 0-th - basically it's a batch dimension) - `torch.meshgrid`\n",
    "\n",
    "For display use `print` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3243.3999,   44.2000, 4242.3999])\n",
      "tensor([[[[0.8923, 0.1496, 0.6169,  ..., 0.3385, 0.9233, 0.1986],\n",
      "          [0.4675, 0.5498, 0.4347,  ..., 0.5428, 0.0798, 0.9068],\n",
      "          [0.3385, 0.4136, 0.1666,  ..., 0.5802, 0.3332, 0.7005],\n",
      "          ...,\n",
      "          [0.3493, 0.0746, 0.4280,  ..., 0.3730, 0.8603, 0.8630],\n",
      "          [0.3617, 0.5209, 0.7110,  ..., 0.9962, 0.9313, 0.0066],\n",
      "          [0.3867, 0.6721, 0.9795,  ..., 0.6605, 0.6939, 0.7924]],\n",
      "\n",
      "         [[0.0058, 0.4261, 0.6261,  ..., 0.6547, 0.0771, 0.2977],\n",
      "          [0.5396, 0.8143, 0.4989,  ..., 0.7205, 0.4818, 0.7665],\n",
      "          [0.0960, 0.8016, 0.5131,  ..., 0.0339, 0.6216, 0.0434],\n",
      "          ...,\n",
      "          [0.0928, 0.9321, 0.3156,  ..., 0.3496, 0.6269, 0.1172],\n",
      "          [0.6237, 0.2330, 0.2168,  ..., 0.1342, 0.0200, 0.7097],\n",
      "          [0.9882, 0.4323, 0.0363,  ..., 0.9289, 0.7874, 0.6920]],\n",
      "\n",
      "         [[0.6516, 0.6148, 0.4989,  ..., 0.5707, 0.8747, 0.9217],\n",
      "          [0.5437, 0.8809, 0.5970,  ..., 0.0785, 0.9608, 0.8054],\n",
      "          [0.7978, 0.6968, 0.5245,  ..., 0.9171, 0.3059, 0.7607],\n",
      "          ...,\n",
      "          [0.1983, 0.7339, 0.3440,  ..., 0.5204, 0.1936, 0.3867],\n",
      "          [0.9880, 0.4636, 0.1709,  ..., 0.5770, 0.4604, 0.6801],\n",
      "          [0.2621, 0.2196, 0.0230,  ..., 0.8233, 0.3943, 0.3269]]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[[[0.3603, 0.5803, 0.7111,  ..., 0.6993, 0.8263, 0.5473],\n",
      "          [0.7178, 0.9979, 0.0915,  ..., 0.0546, 0.8375, 0.7031],\n",
      "          [0.7075, 0.5268, 0.1421,  ..., 0.8609, 0.7143, 0.0645],\n",
      "          ...,\n",
      "          [0.8727, 0.0543, 0.5135,  ..., 0.5004, 0.3992, 0.1015],\n",
      "          [0.2723, 0.3848, 0.7865,  ..., 0.8251, 0.9397, 0.9464],\n",
      "          [0.8845, 0.1047, 0.2343,  ..., 0.9505, 0.8814, 0.3351]],\n",
      "\n",
      "         [[0.9648, 0.9104, 0.3839,  ..., 0.2866, 0.5559, 0.2838],\n",
      "          [0.7864, 0.9424, 0.1281,  ..., 0.1453, 0.0402, 0.2687],\n",
      "          [0.6260, 0.9022, 0.0954,  ..., 0.3090, 0.9182, 0.4954],\n",
      "          ...,\n",
      "          [0.0603, 0.6084, 0.5675,  ..., 0.6922, 0.6073, 0.8958],\n",
      "          [0.0371, 0.9346, 0.0317,  ..., 0.4017, 0.3206, 0.6137],\n",
      "          [0.0632, 0.8076, 0.1472,  ..., 0.4787, 0.4528, 0.9222]],\n",
      "\n",
      "         [[0.4204, 0.2505, 0.8635,  ..., 0.3978, 0.0997, 0.4800],\n",
      "          [0.7184, 0.9827, 0.7496,  ..., 0.5341, 0.2140, 0.9641],\n",
      "          [0.5092, 0.6868, 0.9775,  ..., 0.1398, 0.6275, 0.0380],\n",
      "          ...,\n",
      "          [0.6226, 0.0275, 0.1233,  ..., 0.1094, 0.7451, 0.6162],\n",
      "          [0.7684, 0.8577, 0.9508,  ..., 0.3682, 0.1247, 0.3552],\n",
      "          [0.0401, 0.8419, 0.4032,  ..., 0.3284, 0.2487, 0.1261]]]])\n",
      "tensor([[[[-5.0000, -4.9915, -4.9830,  ..., -4.7873, -4.7788, -4.7703],\n",
      "          [-4.7618, -4.7533, -4.7448,  ..., -4.5491, -4.5406, -4.5321],\n",
      "          [-4.5236, -4.5151, -4.5066,  ..., -4.3109, -4.3024, -4.2939],\n",
      "          ...,\n",
      "          [ 0.9549,  0.9634,  0.9719,  ...,  1.1676,  1.1761,  1.1846],\n",
      "          [ 1.1931,  1.2016,  1.2101,  ...,  1.4058,  1.4143,  1.4228],\n",
      "          [ 1.4313,  1.4398,  1.4483,  ...,  1.6440,  1.6525,  1.6610]],\n",
      "\n",
      "         [[ 1.6695,  1.6780,  1.6865,  ...,  1.8822,  1.8907,  1.8992],\n",
      "          [ 1.9077,  1.9162,  1.9247,  ...,  2.1204,  2.1289,  2.1374],\n",
      "          [ 2.1459,  2.1544,  2.1629,  ...,  2.3586,  2.3671,  2.3756],\n",
      "          ...,\n",
      "          [ 7.6244,  7.6329,  7.6414,  ...,  7.8371,  7.8456,  7.8541],\n",
      "          [ 7.8626,  7.8711,  7.8796,  ...,  8.0753,  8.0838,  8.0923],\n",
      "          [ 8.1008,  8.1093,  8.1178,  ...,  8.3135,  8.3220,  8.3305]],\n",
      "\n",
      "         [[ 8.3390,  8.3475,  8.3560,  ...,  8.5517,  8.5602,  8.5687],\n",
      "          [ 8.5772,  8.5857,  8.5942,  ...,  8.7899,  8.7984,  8.8069],\n",
      "          [ 8.8154,  8.8239,  8.8324,  ...,  9.0281,  9.0366,  9.0451],\n",
      "          ...,\n",
      "          [14.2939, 14.3024, 14.3109,  ..., 14.5066, 14.5151, 14.5236],\n",
      "          [14.5321, 14.5406, 14.5491,  ..., 14.7448, 14.7533, 14.7618],\n",
      "          [14.7703, 14.7788, 14.7873,  ..., 14.9830, 14.9915, 15.0000]]]])\n",
      "tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]]])\n",
      "tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[1, 1, 1,  ..., 1, 1, 1],\n",
      "          [1, 1, 1,  ..., 1, 1, 1],\n",
      "          [1, 1, 1,  ..., 1, 1, 1],\n",
      "          ...,\n",
      "          [1, 1, 1,  ..., 1, 1, 1],\n",
      "          [1, 1, 1,  ..., 1, 1, 1],\n",
      "          [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "         [[2, 2, 2,  ..., 2, 2, 2],\n",
      "          [2, 2, 2,  ..., 2, 2, 2],\n",
      "          [2, 2, 2,  ..., 2, 2, 2],\n",
      "          ...,\n",
      "          [2, 2, 2,  ..., 2, 2, 2],\n",
      "          [2, 2, 2,  ..., 2, 2, 2],\n",
      "          [2, 2, 2,  ..., 2, 2, 2]]]])\n",
      "tensor([[[[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "          ...,\n",
      "          [25, 25, 25,  ..., 25, 25, 25],\n",
      "          [26, 26, 26,  ..., 26, 26, 26],\n",
      "          [27, 27, 27,  ..., 27, 27, 27]],\n",
      "\n",
      "         [[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "          ...,\n",
      "          [25, 25, 25,  ..., 25, 25, 25],\n",
      "          [26, 26, 26,  ..., 26, 26, 26],\n",
      "          [27, 27, 27,  ..., 27, 27, 27]],\n",
      "\n",
      "         [[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "          [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "          [ 2,  2,  2,  ...,  2,  2,  2],\n",
      "          ...,\n",
      "          [25, 25, 25,  ..., 25, 25, 25],\n",
      "          [26, 26, 26,  ..., 26, 26, 26],\n",
      "          [27, 27, 27,  ..., 27, 27, 27]]]])\n",
      "tensor([[[[ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          ...,\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27]],\n",
      "\n",
      "         [[ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          ...,\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27]],\n",
      "\n",
      "         [[ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          ...,\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27],\n",
      "          [ 0,  1,  2,  ..., 25, 26, 27]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/.local/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "shape = (1,3,28,28)\n",
    "\n",
    "# a\n",
    "t = torch.tensor([3243.4, 44.2, 4242.4], dtype=torch.float32)\n",
    "print(t)\n",
    "# b\n",
    "a = np.random.rand(*shape)\n",
    "t = torch.from_numpy(a)\n",
    "print(t)\n",
    "# c\n",
    "torch.manual_seed(43543)\n",
    "t = torch.rand(shape)\n",
    "print(t)\n",
    "# d\n",
    "t = torch.linspace(-5,15, shape[0]*shape[1]*shape[2]*shape[3]).reshape(shape)\n",
    "print(t)\n",
    "# e\n",
    "x0 = torch.arange(shape[0])\n",
    "x1 = torch.arange(shape[1])\n",
    "x2 = torch.arange(shape[2])\n",
    "x3 = torch.arange(shape[3])\n",
    "x0, x1, x2, x3 = torch.meshgrid(x0,x1,x2,x3)\n",
    "print(x0)\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. PyTorch allow for applying GPU for computations.\n",
    "Check if gpu (CUDA) is available, then use it as `device`, else use `'cpu'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor([43, 43], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "t = torch.tensor([43,43], device=device)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. To train a networks we need a dataset. \n",
    "\n",
    "Please download `MINIST` dataset with `torchvision.dataset`.\n",
    "\n",
    "For any kind of ML tasks, validation and/or testing is required.\n",
    "\n",
    "So, create train and test datasets.\n",
    "\n",
    "For train dataset apply also augmentation transforms, crop, translation and rotation.\n",
    "\n",
    "You can try to apply different transforms.\n",
    "\n",
    "For both apply ToTensor.\n",
    "\n",
    "Next, pack datasets into `DataLoader`s with batch size of 64.\n",
    "Use variables with names: `train_loader` and `test_loader`. \n",
    "\n",
    "Next display sizes of datasets, shapes of elements and display few images (`plt.gray()`,`plt.imshow()`) and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_dataset = ...\n",
    "train_dataset = ...\n",
    "...\n",
    "\n",
    "train_loader = ...\n",
    "test_loader = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. `*`Additionally, you can prepare analysis of datasets. \n",
    "\n",
    "E.g. statistics like mean and variance of all elements, for each label.\n",
    "\n",
    "Analysis can allow you for designing better network architecture.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. When we have datasets, we can create model for classification task.\n",
    "\n",
    "Please, define class `MLP` as Multi Layer Perceptron \n",
    "\n",
    "with two hidden fully connected layers with bias.\n",
    "\n",
    "Class must inherits from `torch.nn.Module`.\n",
    "\n",
    "Apply following configuration:\n",
    "\n",
    "- first with 512 neurons,\n",
    "- second with 512 neurons,\n",
    "- output layer adjust to size of classification problem.\n",
    "\n",
    "For `__init__` method add parameters: input_shape and output_size.\n",
    "\n",
    "Hidden layers sizes can also be parametrized. \n",
    "\n",
    "Don't forget about nonlinearities! \n",
    "\n",
    "For hidden layers you can use `ReLU` module from `torch.nn`.\n",
    "\n",
    "For output apply softmax function / layers.\n",
    "\n",
    "Network layer-by-layer processing define in `forward` method with argument as a network \n",
    "\n",
    "input tensor - batch of images with shape (batch_size, channels, height, width).\n",
    "(channels = 1, for gray scale images)\n",
    "\n",
    "Instantiate model as `net` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(...):\n",
    "\n",
    "    def __init__(self, ) -> None:\n",
    "        super().__init__()\n",
    "        ...\n",
    "        \n",
    "    def forward(sefl, x: torch.Tensor) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "\n",
    "net = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. To train network we need to know 'how good or bad' results it gives.\n",
    "Please, instantiate `torch.nn.CrossEntropyLoss` as `loss_fcn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. To score network define accuracy metric.\n",
    "\n",
    "For network output you need to decide what is the final network answer(`argmax`).\n",
    "\n",
    "`torch.no_grad()` prevents gradient requirement for computations inside method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class BaseMetic(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, y_pred, y_ref) -> Any:\n",
    "        raise NotImplementedError()    \n",
    "    \n",
    "    \n",
    "class AccuracyMetic(BaseMetic):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, y_pred: torch.Tensor, y_ref: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param y_pred: tensor of shape (batch_size, num_of_classes) type float\n",
    "        :param y_ref: tensor with shape (batch_size,) and type Long\n",
    "        :return: scalar tensor with accuracy metric for batch\n",
    "        \"\"\"\n",
    "        # scalar value\n",
    "        score: torch.Tensor = ...\n",
    "        \n",
    "        return score\n",
    "\n",
    "\n",
    "metric = AccuracyMetic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. To change network parameters, we need optimizers object.\n",
    "Instantiate `torch.optim.SGD` (with `net`work parameters) as `optimizer`.\n",
    "Use learning rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Now define training / testing function:\n",
    "\n",
    "Util functions: `tensor.backward`, `torch.nn.module()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def train(model, \n",
    "          data_generator, \n",
    "          criterion, \n",
    "          metric: BaseMetic,\n",
    "          optimizer: torch.optim.Optimizer = None, \n",
    "          update_period: int = None,\n",
    "          mode: str = 'test',\n",
    "          device = torch.device('cpu')) -> Tuple[torch.nn.Module, float, float]:\n",
    "    \n",
    "    # change model mode to train or test\n",
    "    if mode == 'train':\n",
    "        ...\n",
    "        \n",
    "    elif mode == 'test':\n",
    "        ...\n",
    "        \n",
    "    else:\n",
    "        raise RuntimeError(\"Unsupported mode.\")\n",
    "\n",
    "    # move model to device\n",
    "    \n",
    "    # reset model parameters' gradients with optimizer\n",
    "    if mode == 'train':\n",
    "        ...\n",
    "    \n",
    "    total_loss: float = 0.0\n",
    "    total_accuracy: float = 0.0\n",
    "    samples_num: int = 0\n",
    "    \n",
    "    for i, (X, y) in tqdm.tqdm(enumerate(data_generator)):\n",
    "        # convert tensors to device\n",
    "        ...\n",
    "        \n",
    "        # depending on mode use or not torch.no_grad() as 'with' block\n",
    "        ...\n",
    "        \n",
    "        # process by network\n",
    "        y_pred = ...\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = ...\n",
    "        \n",
    "        # designate gradient based on loss\n",
    "        ...\n",
    "        \n",
    "        if mode == 'train' and (i+1) % update_period:\n",
    "            # update parameters with optimizer\n",
    "            ...\n",
    "        \n",
    "        # calculate accuracy\n",
    "        accuracy = ...\n",
    "        \n",
    "        total_loss += loss.item() * y_pred.shape[0]\n",
    "        total_accuracy += accuracy.item() * y_pred.shape[0]\n",
    "        samples_num += y_pred.shape[0]\n",
    "    \n",
    "    if samples_num == 0:\n",
    "        return model, 0.0, 0.0\n",
    "    \n",
    "    return model, total_loss / samples_num, total_accuracy / samples_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Prepare training loop (over epochs) function:\n",
    "- adjust max number of epochs to achieve satisfactory results.\n",
    "- `**` additionally, implement auto-detection of bias-variance tradeoff point, to break further training.\n",
    "- `***` additionally, use learning rate scheduler.\n",
    "- for each epoch collect losses and accuracies for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Display training history (`plt.plot`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Save model and optimizer states to files.\n",
    "\n",
    "Use method `state_dict` and function `torch.save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Create new network with the same architecture and initialize it with saved weights.\n",
    "\n",
    "`torch.load`, `load_state_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Define your own model and train it.\n",
    "\n",
    "Try achieve better results.\n",
    "\n",
    "You can use different parameters, layers e.g.:\n",
    "- conv2d\n",
    "- maxpooling2d\n",
    "- batch norm 2d\n",
    "- and more...\n",
    "\n",
    "Save weights to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. You can leave a feedback, if you want :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Send (e-mail) your results(notebook+weights) in a *.zip file\n",
    "\n",
    "or (preferred) send link to your's github repository with your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
