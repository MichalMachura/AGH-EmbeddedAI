{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization - introduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# default size of figures\n",
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization is a process of representation change: from real values to discrete space.\n",
    "\n",
    "Floating point representation has good enough precision to assume it as a real value.\n",
    "\n",
    "As our discrete space, we select fixed point representation with:\n",
    "- sign (most significant bit (MSB))\n",
    "- width of 8 bits\n",
    "- point position after second bit (counted from the less significant bit (LSB)) (precision).\n",
    "\n",
    "Note: bit of sign is one of integer bits.\n",
    "\n",
    "Process of quantization is based on few steps:\n",
    "\n",
    "1) transformation real value $V$ to discrete space $q$:\n",
    "\n",
    "$q = \\max\\left(0; \\min\\left(UINT\\_MAX;round \\left(\\frac{V}{precision} - offset \\right) \\right)\\right)$\n",
    "\n",
    "2) retransformation from discrete space to floating point space:\n",
    "\n",
    "$Q = precision \\times \\left(q - offset \\right)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate number of integer bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNED = 1\n",
    "BIT_WIDTH = 4\n",
    "PRECISION_BITS = 2  # point position\n",
    "\n",
    "INT_BITS = ...\n",
    "\n",
    "# SIGN bit is also integer bit !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To perform quantization, there is needed a set of real values.\n",
    "\n",
    "Please, create a tensor `R` with values from linear space of range -2.5 to 2.5 and length of 1000 elements.\n",
    "\n",
    "Plot tensor on both axis X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = torch.linspace(start, end, steps)\n",
    "\n",
    "plt.plot(X, Y, label='Label for Y')\n",
    "plt.title(\"Title of figure\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Determinate some descriptive constants of fixed point representation:\n",
    "- MIN_INT_VALUE  - for the whole representation, so for integer on `BIT_WIDTH` \n",
    "- MAX_UINT_VALUE  - for the whole representation, so for unsigned integer on `BIT_WIDTH`\n",
    "- PRECISION - distance between next fixed point numbers, based on `PRECISION_BITS`(size of fractional part) - minimal fractional value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tasks 4 - 9 plot resulted tensors.\n",
    "\n",
    "Add XY labels, title, legend.\n",
    "\n",
    "As X coordinates use `R` tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Scale: Transform tensor `R` to \"continues integer\" space:\n",
    "\n",
    "Hint: use `PRECISION`.\n",
    "\n",
    "Result tensor: `scaled`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Translate: Transform tensor `scaled` to \"continues unsigned integer\" space:\n",
    "\n",
    "Hint: use `MIN_INT_VALUE`.\n",
    "\n",
    "Result tensor: `translated`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Round: Transform tensor `translated` to discrete space with `floor` method:\n",
    "\n",
    "This operation is the main part of quantization.\n",
    "\n",
    "It is not possible to revert this operation.\n",
    "\n",
    "Result tensor: `rounded`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Limit: Limit tensor `rounded` to range `[0;MAX_UINT_VALUE]`:\n",
    "\n",
    "It is not possible to revert this operation, the same as previous.\n",
    "\n",
    "Result tensor: `limited`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Retranslate: Transform tensor `limited` to integer space:\n",
    "\n",
    "Hint: see point 5.\n",
    "\n",
    "Result tensor: `retranslated`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retranslated = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Rescale: Transform tensor `retranslated` to real space:\n",
    "\n",
    "Hint: see point 4.\n",
    "\n",
    "Result tensor: `rescaled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Assign `rescaled` tensor to `quantized` variable.\n",
    "\n",
    "Plot `quantized` and `R` tensors on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Based on the steps 3 - 9 define a function `fixed_point_quantize`.\n",
    "\n",
    "Function should takes arguments:\n",
    "- `R` - floating point tensor, which will be quantized\n",
    "- `bit_width` - fixed point bit width\n",
    "- `precision_bits` - number of precision bits / point position\n",
    "- `round_method` - method of rounding, one of 'round', 'floor', 'ceil'.\n",
    "\n",
    "Function should return quantized tensor.\n",
    "\n",
    "Note: Do not plot anything inside function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_fixed_point_quantize(R: torch.Tensor,\n",
    "                                bit_width: int,\n",
    "                                precision_bits: int,\n",
    "                                round_method:str = 'round') -> torch.Tensor:\n",
    "    ...\n",
    "    quantized = ...\n",
    "    \n",
    "    return quantized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Test function on previously created `R` tensor.\n",
    "\n",
    "Display results in the same way as in point 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. `*` Additional:\n",
    "\n",
    "Define unsigned quantization function and test it on `R` tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsigned_fixed_point_quantize(R: torch.Tensor,\n",
    "                                  bit_width: int,\n",
    "                                  precision_bits: int,\n",
    "                                  round_method:str = 'round') -> torch.Tensor:\n",
    "    ...\n",
    "    quantized = ...\n",
    "    \n",
    "    return quantized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. `**` Additional:\n",
    "\n",
    "Apply quantization on image `mandrill.jpg`.\n",
    "\n",
    "Use opencv function `imread` to read image with arguments: path_to_file and value 0 (as second arg).\n",
    "\n",
    "Function returns numpy ndarray. Convert it to torch.Tensor and divide by 255 (normalization).\n",
    "\n",
    "Display image with `plt.imshow`.\n",
    "\n",
    "Apply signed quantization of 4 bits, 3 bits of precision and 'floor' rounding.\n",
    "\n",
    "Plot resultant image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv # import opencv package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. You can leave a feedback, if you want :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Exercises please upload this file (*.ipynb) to UPEL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
