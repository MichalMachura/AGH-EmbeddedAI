{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nvidia Jestson Nano\n",
    "\n",
    "Nvidia Jetson Nano (JN) is an embedded GPU platform that supports CUDA technology.\n",
    "\n",
    "Board contains (among others) ports:\n",
    "- HDMI(display)\n",
    "- USB-C (power supply)\n",
    "- 3x USB 3.0 - keyboard, mouse and more like USB camera.\n",
    "- RJ-45 (ethernet) port\n",
    "- micro USB port,\n",
    "- GPIO ports...\n",
    "\n",
    "JN is a computer with CPU and GPU.\n",
    "\n",
    "Works under Linux OS control.\n",
    "\n",
    "Support remote mode and independent - like normal PC with keyboard, mouse and display.\n",
    "\n",
    "This exercise is based on remote mode with command line interface and web / browser through jupyter notebook server on JS board. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation, tutorials, etc.:\n",
    "- https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-2gb-devkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0 - run on each device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for MNIST dataset\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "from typing import Tuple, Union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To be able to compare acceleration capabilities, we need to measure execution time.\n",
    "\n",
    "Your task is to define [context manager](https://www.geeksforgeeks.org/context-manager-in-python/) class :\n",
    "- class name: `TimeMeasurement`\n",
    "- manager should be initialized with number of 'predicted' processed frames as `int` \n",
    "\n",
    "(number of processed images in context) and context name as `str` \n",
    "- when entering the context, manager should save current time\n",
    "- when exiting the context, manager should save current time\n",
    "- manager should calculate duration of context execution in seconds (floats) getter [property](https://www.geeksforgeeks.org/python-property-decorator-property/) `time`\n",
    "- manager should calculate fps by getter property `fps` during context execution\n",
    "- overload method `__str__` to display context in format `Execution time: {hours}:{minutes}:{seconds}:{milliseconds}, processed {frames_num} frames, throughput: {fps} fps.`\n",
    "- overload method `__repr__` to display context in format `TimeMeasurement(context=\"{context_name}\",\"{hours}:{minutes}:{seconds}:{milliseconds}\", frames={frames_num}, throughput={fps})`\n",
    "\n",
    "Node: Prevent situation when properties `time` and `fps` are called, \n",
    "\n",
    "when context is still not closed or not opened (when there is no time data of beginning and ending of context).\n",
    "\n",
    "In this situation raise RuntimeError exception.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class TimeMeasurement:\n",
    "    def __init__(self, context_name: str, frames: int) -> None:\n",
    "        # initialize needed object attributes\n",
    "        # use passed arguments or None\n",
    "        ...\n",
    "    # context methods\n",
    "    ...\n",
    "        \n",
    "    # time and fps properties\n",
    "    ...\n",
    "    \n",
    "    # __str__ and __repr__ methods\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Test defined context manager by running in context 1000 for loop iterations with `time.sleep` of `1 ms`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TimeMeasurement(\"Test\", ...)\n",
    "\n",
    "with tm:\n",
    "    # iterate 1000 times\n",
    "    for i in ...:\n",
    "        # sleep for 0.001 s\n",
    "        ...\n",
    "\n",
    "print(\"fps = \", ..., \"[fps]\") # print fps properties values\n",
    "print(\"time = \", ..., \"[s]\") # print time properties values\n",
    "print(repr(tm))\n",
    "print(str(tm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating evaluation dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = datasets.MNIST('data', \n",
    "                              train=False,\n",
    "                              download=True,\n",
    "                              transform=ToTensor())\n",
    "eval_loader = DataLoader(eval_dataset, \n",
    "                          batch_size=1, # batch size of 1 for real time processing\n",
    "                          shuffle=False)\n",
    "print(\"len(eval_loader) =\", len(eval_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import local_utils \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_channels: int,\n",
    "                 intermediate_channels: int,\n",
    "                 kernel_size: Union[int, Tuple[int,int]],                  \n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        self.L1 = nn.Sequential(nn.Conv2d(in_channels=input_channels, \n",
    "                                          out_channels=intermediate_channels, \n",
    "                                          kernel_size=kernel_size, \n",
    "                                          bias=False, \n",
    "                                          padding=kernel_size//2),\n",
    "                                nn.BatchNorm2d(intermediate_channels),\n",
    "                                nn.ReLU()\n",
    "                                )\n",
    "        self.L2 = nn.Sequential(nn.Conv2d(in_channels=intermediate_channels, \n",
    "                                          out_channels=input_channels, \n",
    "                                          kernel_size=kernel_size, \n",
    "                                          bias=False, \n",
    "                                          padding=kernel_size//2),\n",
    "                                nn.BatchNorm2d(input_channels),\n",
    "                                nn.ReLU()\n",
    "                                )\n",
    "        \n",
    "    def forward(self, \n",
    "                x: torch.Tensor) -> torch.Tensor:\n",
    "        return x + self.L2(self.L1(x))\n",
    "\n",
    "\n",
    "class MiniResNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape=(1,28,28),\n",
    "                 num_of_classes=10,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        self.CNN = nn.Sequential(\n",
    "                                nn.Conv2d(input_shape[0], 16, 3, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                \n",
    "                                ResidualBlock(16,4,3),\n",
    "                                \n",
    "                                nn.Conv2d(16, 32, 3, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(2,2),\n",
    "                                \n",
    "                                ResidualBlock(32,4,3),\n",
    "                                ResidualBlock(32,2,3),\n",
    "                                \n",
    "                                nn.Conv2d(32, 64, 3, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(2,2),\n",
    "                                \n",
    "                                ResidualBlock(64,8,3),\n",
    "                                ResidualBlock(64,16,3),\n",
    "                                \n",
    "                                nn.Conv2d(64, 128, 3),\n",
    "                                nn.ReLU(),\n",
    "                                \n",
    "                                nn.Conv2d(128, 128, 3),\n",
    "                                nn.ReLU(),\n",
    "                                )\n",
    "        CNN_out_shape = [\n",
    "                         128,\n",
    "                         input_shape[-2]//2//2 - 3//2*2 - 3//2*2,\n",
    "                         input_shape[-1]//2//2 - 3//2*2 - 3//2*2\n",
    "                        ]\n",
    "        CNN_flatten_len = torch.prod(torch.tensor(CNN_out_shape))\n",
    "        \n",
    "        self.FC = nn.Sequential(\n",
    "                               nn.Flatten(),\n",
    "                               nn.Linear(CNN_flatten_len, num_of_classes),\n",
    "                               nn.Softmax(1),\n",
    "                               )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.FC(self.CNN(x))\n",
    "        \n",
    "\n",
    "net = MiniResNet((1,28,28), 10)\n",
    "\n",
    "print(f\"Num of parameter: {local_utils.count_params(net)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy metric  and cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = local_utils.AccuracyMetic()\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - TRAINING\n",
    "\n",
    "Cells in this section run only when you are on host device - PC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = datasets.MNIST('data', \n",
    "                              train=True,\n",
    "                              download=True,\n",
    "                              transform=ToTensor())\n",
    "test_dataset = datasets.MNIST('data', \n",
    "                              train=False,\n",
    "                              download=True,\n",
    "                              transform=ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False)\n",
    "print(\"len(train_loader) =\", len(train_loader))\n",
    "print(\"len(test_loader) =\", len(test_loader))\n",
    "\n",
    "plt.gray()\n",
    "loader = train_loader\n",
    "for X, y in loader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    ROWS, COLS = 1, 4\n",
    "    fig, axs = plt.subplots(ROWS, COLS)\n",
    "    fig.set_size_inches(COLS*4,ROWS*4)\n",
    "    axs = np.array(axs).flatten().tolist()\n",
    "    \n",
    "    for i, ax in enumerate(axs):\n",
    "        img = X[i,...]\n",
    "        class_label = loader.dataset.classes[y[i]]\n",
    "        ax.imshow(img.permute(1,2,0))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train the network with:\n",
    "- SGD optimizer\n",
    "- learning rate 0.1\n",
    "- update period of 5\n",
    "- 5 epochs\n",
    "\n",
    "Plot history and print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = local_utils.AccuracyMetic()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "net.to(device)\n",
    "net, history = local_utils.training(...)\n",
    "\n",
    "local_utils.plot_history(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extract model state dict and save it in file `weights.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = ...\n",
    "torch.save(sd, 'weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - EVALUATION - host device\n",
    "Do not run cells from this section on Jetson Nano (to avoid output overwriting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Instantiate `MiniResNet` network with the same input shape.\n",
    "\n",
    "Load state dict from `weights.pth` file and initialize with them network (`load_state_dict`, with `map_location=device`).  \n",
    "\n",
    "Evaluate model on `eval_loader` dataset with `local_utils.train_test_pass`.\n",
    "\n",
    "Print information about loss, accuracy, time of execution, number of processed images and throughput (fps).\n",
    "\n",
    "Experiment do for 'cpu' and for 'cuda' devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA - GPU\n",
    "device = ...\n",
    "# load sd with mapping location to device\n",
    "sd = ...\n",
    "# create net and move it to device\n",
    "net = ...\n",
    "# load state dict to net\n",
    "net.load_state_dict(sd)\n",
    "\n",
    "tm = TimeMeasurement(\"Host-GPU\", len(eval_loader))\n",
    "\n",
    "with tm:\n",
    "    ...\n",
    "    # evaluate model on device use local_utils.train_test_pass\n",
    "    \n",
    "print(repr(tm))\n",
    "print(\"loss:\", loss)\n",
    "print(\"acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU\n",
    "device = ...\n",
    "# load sd with mapping location to device\n",
    "sd = ...\n",
    "# create net and move it to device\n",
    "net = ...\n",
    "# load state dict to net\n",
    "net.load_state_dict(sd)\n",
    "\n",
    "tm = TimeMeasurement(\"Host-CPU\", len(eval_loader))\n",
    "\n",
    "with tm:\n",
    "    ...\n",
    "    # evaluate model on device use local_utils.train_test_pass\n",
    "    \n",
    "print(repr(tm))\n",
    "print(\"loss:\", loss)\n",
    "print(\"acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Connection - Jetson Nano - for the next lab 01.12.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with Jetson Nano board (JNb):\n",
    "\n",
    "1 ) Connect Power supplier plugin to the socket and USB-C plugin to the board.\n",
    "\n",
    "2 ) On the host side run command in terminal:\n",
    "\n",
    "`dmesg | grep --color 'tty'`\n",
    "\n",
    "This should print all USB devices.\n",
    "     \n",
    "3 ) Connect micro USB cable between PC and JNb.\n",
    "\n",
    "4 ) Run again command from `2)`. \n",
    "\n",
    "Find new device - that's Jetson Nano!\n",
    "\n",
    "Output should look similar to:\n",
    "\n",
    "`[xxxxxx.xxxxxx] cdc_acm 1-5:1.2: ttyACM0: USB ACM device`\n",
    "\n",
    "`ttyACM0` is USB device name.\n",
    "\n",
    "5 ) Run command:\n",
    "\n",
    "`ls -l /dev/ttyACM0`\n",
    "\n",
    "Output should look similar to:\n",
    "\n",
    "`crw-rw---- 1 root dialout 166, 0 Oct  2 02:45 /dev/ttyACM0`\n",
    "\n",
    "6 ) Install `screen`:\n",
    "\n",
    "`sudo apt-get update`\n",
    "\n",
    "`sudo apt install screen`\n",
    "\n",
    "7 ) Connect with JNb:\n",
    "\n",
    "`sudo screen /dev/ttyACM0 115200`\n",
    "\n",
    "8 ) Now you are in the remote terminal of JNb.\n",
    "\n",
    "(user: `nano`, paswd: `nano`)\n",
    "\n",
    "9 ) Run Jupyter server on the board:\n",
    "\n",
    "`jupyter notebook`\n",
    "\n",
    "10 ) Open displayed link ([192.168.55.1:8888/eAI](192.168.55.1:8888/eAI)) in browser. (user: `nano`, paswd: `nano`)\n",
    "\n",
    "11 ) Create your own directory structure (the final path name should be `$DIR_NAME = ./eAI/{your_name}/lab8` relatively to main the root directory of server).\n",
    "\n",
    "12 ) Now save this file and upload it to JNb by browser interface to `$DIR_NAME` directory.\n",
    "\n",
    "13 ) Upload also `data` directory, `local_utils.py` and saved `weights.pth` file to `$DIR_NAME` directory. \n",
    "\n",
    "14 ) Run jupyter notebook (browser version) \n",
    "\n",
    "15 ) Run cells from part 0 and 4.\n",
    "\n",
    "16) Save notebook and download it back to the host.\n",
    "\n",
    "17) Run terminal in jupyter web/browser ![terminal icon](image.png)\n",
    "\n",
    "18) Shutdown Jetson Nano by command `shutdown -h now`\n",
    "\n",
    "19) Disconnect Jetson Nano Board from power supply and micro-USB\n",
    "\n",
    "20) Upload notebook to the UPEL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - EVALUATION - Jetson Nano device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Instantiate `MiniResNet` network with the same input shape.\n",
    "\n",
    "Load state dict from `weights.pth` file and initialize with them network (`load_state_dict`).  \n",
    "\n",
    "Evaluate model on `eval_loader` dataset with `local_utils.train_test_pass` on Jetson Nano Device.\n",
    "\n",
    "Print information about loss, accuracy, time of execution, number of processed images and throughput (fps).\n",
    "\n",
    "Experiment do for 'cpu' and for 'cuda' devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU\n",
    "device = ...\n",
    "# load sd with mapping location to device\n",
    "sd = ...\n",
    "# create net and move it to device\n",
    "net = ...\n",
    "# load state dict to net\n",
    "net.load_state_dict(sd)\n",
    "\n",
    "tm = TimeMeasurement(\"Jetson Nano - CPU\", len(eval_loader))\n",
    "\n",
    "with tm:\n",
    "    ...\n",
    "    # evaluate model on device use local_utils.train_test_pass\n",
    "    \n",
    "print(repr(tm))\n",
    "print(\"loss:\", loss)\n",
    "print(\"acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA - GPU\n",
    "device = ...\n",
    "# load sd with mapping location to device\n",
    "sd = ...\n",
    "# create net and move it to device\n",
    "net = ...\n",
    "# load state dict to net\n",
    "net.load_state_dict(sd)\n",
    "\n",
    "tm = TimeMeasurement(\"Jetson Nano - GPU\", len(eval_loader))\n",
    "\n",
    "with tm:\n",
    "    ...\n",
    "    # evaluate model on device use local_utils.train_test_pass\n",
    "    \n",
    "print(repr(tm))\n",
    "print(\"loss:\", loss)\n",
    "print(\"acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Copy / download notebook from Jetson Nano Device to Host PC by web/browser interface or via ftp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. You can leave a feedback, if you want :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Exercises please upload notebook WITH ALL OUTPUTS to UPEL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
